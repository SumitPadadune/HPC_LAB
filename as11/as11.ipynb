{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. Execute the following program and check the properties of your GPGPU."
      ],
      "metadata": {
        "id": "zjBFpZ1v9F3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJ_BfVqQrE5G",
        "outputId": "243e8af9-fbd6-4aef-e17e-1036f99efd79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q1\n",
        "%%writefile cuda_device_info.cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int deviceCount;\n",
        "    cudaGetDeviceCount(&deviceCount);\n",
        "    if (deviceCount == 0) {\n",
        "        printf(\"There is no device supporting CUDA\\n\");\n",
        "    }\n",
        "    int dev;\n",
        "    for (dev = 0; dev < deviceCount; ++dev)\n",
        "    {\n",
        "        cudaDeviceProp deviceProp;\n",
        "        cudaGetDeviceProperties(&deviceProp, dev);\n",
        "        if (dev == 0) {\n",
        "            if (deviceProp.major < 1) {\n",
        "                printf(\"There is no device supporting CUDA.\\n\");\n",
        "            } else if (deviceCount == 1) {\n",
        "                printf(\"There is 1 device supporting CUDA\\n\");\n",
        "            } else {\n",
        "                printf(\"There are %d devices supporting CUDA\\n\", deviceCount);\n",
        "            }\n",
        "        }\n",
        "        printf(\"\\nDevice %d: \\\"%s\\\"\\n\", dev, deviceProp.name);\n",
        "        printf(\"  Major revision number:                         %d\\n\", deviceProp.major);\n",
        "        printf(\"  Minor revision number:                         %d\\n\", deviceProp.minor);\n",
        "        printf(\"  Total amount of global memory:                 %zu bytes\\n\", deviceProp.totalGlobalMem);\n",
        "        printf(\"  Total amount of constant memory:               %zu bytes\\n\", deviceProp.totalConstMem);\n",
        "        printf(\"  Total amount of shared memory per block:       %zu bytes\\n\", deviceProp.sharedMemPerBlock);\n",
        "        printf(\"  Total number of registers available per block: %d\\n\", deviceProp.regsPerBlock);\n",
        "        printf(\"  Warp size:                                     %d\\n\", deviceProp.warpSize);\n",
        "        printf(\"  Multiprocessor count:                          %d\\n\",deviceProp.multiProcessorCount );\n",
        "        printf(\"  Maximum number of threads per block:           %d\\n\", deviceProp.maxThreadsPerBlock);\n",
        "        printf(\"  Maximum sizes of each dimension of a block:    %d x %d x %d\\n\", deviceProp.maxThreadsDim[0],deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2]);\n",
        "        printf(\"  Maximum sizes of each dimension of a grid:     %d x %d x %d\\n\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1],  deviceProp.maxGridSize[2]);\n",
        "        printf(\"  Maximum memory pitch:                          %zu bytes\\n\", deviceProp.memPitch);\n",
        "        printf(\"  Texture alignment:                             %zu bytes\\n\", deviceProp.textureAlignment);\n",
        "        printf(\"  Clock rate:                                    %d kilohertz\\n\", deviceProp.clockRate);\n",
        "    }\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b1JiLNVr9Oq",
        "outputId": "d63d8086-190b-4f21-faa6-69da9dceb2a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cuda_device_info.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc cuda_device_info.cu -o cuda_device_info\n"
      ],
      "metadata": {
        "id": "RwLc7XrgsADX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./cuda_device_info\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAuSQbNpsGLk",
        "outputId": "cb813f25-f4b1-43ad-b3e3-c5d25aeeefce"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is 1 device supporting CUDA\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  Major revision number:                         7\n",
            "  Minor revision number:                         5\n",
            "  Total amount of global memory:                 15835660288 bytes\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Multiprocessor count:                          40\n",
            "  Maximum number of threads per block:           1024\n",
            "  Maximum sizes of each dimension of a block:    1024 x 1024 x 64\n",
            "  Maximum sizes of each dimension of a grid:     2147483647 x 65535 x 65535\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Clock rate:                                    1590000 kilohertz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Q2. Write a program to where each thread prints its thread ID along with hello world. Lauch the kernel with one block and multiple threads.\n"
      ],
      "metadata": {
        "id": "QpgeKhcG9RMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2\n",
        "%%writefile hello_cuda.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "// CUDA kernel\n",
        "__global__ void helloFromThreads() {\n",
        "    int tid = threadIdx.x;\n",
        "    printf(\"Hello World from thread %d\\n\", tid);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int numThreads = 10;\n",
        "    helloFromThreads<<<1, numThreads>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z7xvkGH5i7I",
        "outputId": "45d78543-6cb3-4af5-94af-f46e580226b2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello_cuda.cu -o hello_cuda\n"
      ],
      "metadata": {
        "id": "FzbwiFbj5wyT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello_cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7N7nmQS5zaf",
        "outputId": "fecc516a-da9d-4f74-a9cf-f7db58591e30"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from thread 0\n",
            "Hello World from thread 1\n",
            "Hello World from thread 2\n",
            "Hello World from thread 3\n",
            "Hello World from thread 4\n",
            "Hello World from thread 5\n",
            "Hello World from thread 6\n",
            "Hello World from thread 7\n",
            "Hello World from thread 8\n",
            "Hello World from thread 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Q3. Write a program to where each thread prints its thread ID along with hello world. Lauch the kernel with multiple blocks and multiple threads.\n"
      ],
      "metadata": {
        "id": "W1jPqQPd9Yq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3\n",
        "%%writefile hello_multi_cuda.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "// CUDA kernel\n",
        "__global__ void helloFromThreads() {\n",
        "    // Calculate the global thread ID\n",
        "    int threadID = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Print Hello World along with the thread ID and block index\n",
        "    printf(\"Hello World from block %d, thread %d (Global thread ID: %d)\\n\", blockIdx.x, threadIdx.x, threadID);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Define the number of threads per block and the number of blocks\n",
        "    int threadsPerBlock = 4; // Example: 4 threads per block\n",
        "    int numBlocks = 3;       // Example: 3 blocks\n",
        "\n",
        "    // Launch the kernel with multiple blocks and threads per block\n",
        "    helloFromThreads<<<numBlocks, threadsPerBlock>>>();\n",
        "\n",
        "    // Synchronize to ensure all threads finish before program exits\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IoKC0qV7l2k",
        "outputId": "87acf2e9-31e2-4c0e-91ef-b51ab9ad6ff0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_multi_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello_multi_cuda.cu -o hello_multi_cuda\n"
      ],
      "metadata": {
        "id": "m71EWBII7qZB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello_multi_cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlwoDX6o7spd",
        "outputId": "aa64ae84-71f8-4f1d-bd8d-04ff080a2cfe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from block 2, thread 0 (Global thread ID: 8)\n",
            "Hello World from block 2, thread 1 (Global thread ID: 9)\n",
            "Hello World from block 2, thread 2 (Global thread ID: 10)\n",
            "Hello World from block 2, thread 3 (Global thread ID: 11)\n",
            "Hello World from block 0, thread 0 (Global thread ID: 0)\n",
            "Hello World from block 0, thread 1 (Global thread ID: 1)\n",
            "Hello World from block 0, thread 2 (Global thread ID: 2)\n",
            "Hello World from block 0, thread 3 (Global thread ID: 3)\n",
            "Hello World from block 1, thread 0 (Global thread ID: 4)\n",
            "Hello World from block 1, thread 1 (Global thread ID: 5)\n",
            "Hello World from block 1, thread 2 (Global thread ID: 6)\n",
            "Hello World from block 1, thread 3 (Global thread ID: 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Q4. Write a program to where each thread prints its thread ID along with hello world. Lauch the kernel with 2D blocks and 2D threads.\n"
      ],
      "metadata": {
        "id": "_jqaBeKw9dj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4\n",
        "%%writefile hello_2d_cuda.cu\n",
        "#include <stdio.h>\n",
        "\n",
        "// CUDA kernel\n",
        "__global__ void helloFrom2DThreads() {\n",
        "    // Get the thread ID in the 2D grid\n",
        "    int threadID_x = threadIdx.x;\n",
        "    int threadID_y = threadIdx.y;\n",
        "\n",
        "    int blockID_x = blockIdx.x;\n",
        "    int blockID_y = blockIdx.y;\n",
        "\n",
        "    // Print Hello World along with the thread and block IDs\n",
        "    printf(\"Hello World from block (%d, %d), thread (%d, %d)\\n\", blockID_x, blockID_y, threadID_x, threadID_y);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    // Define the block and grid dimensions\n",
        "    dim3 threadsPerBlock(4, 4); // 4x4 threads per block (2D thread configuration)\n",
        "    dim3 numBlocks(2, 2);       // 2x2 blocks (2D block configuration)\n",
        "\n",
        "    // Launch the kernel with 2D grid and 2D block dimensions\n",
        "    helloFrom2DThreads<<<numBlocks, threadsPerBlock>>>();\n",
        "\n",
        "    // Synchronize to ensure all threads finish before program exits\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELtG4SnU6faT",
        "outputId": "0a0ee7bd-9b3e-4958-a80c-327f69d640d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_2d_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc hello_2d_cuda.cu -o hello_2d_cuda\n"
      ],
      "metadata": {
        "id": "23eObKEz6ivH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./hello_2d_cuda\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebRw-lWb6l8k",
        "outputId": "d4908e7d-5403-47ae-9426-58edfa422795"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World from block (0, 1), thread (0, 0)\n",
            "Hello World from block (0, 1), thread (1, 0)\n",
            "Hello World from block (0, 1), thread (2, 0)\n",
            "Hello World from block (0, 1), thread (3, 0)\n",
            "Hello World from block (0, 1), thread (0, 1)\n",
            "Hello World from block (0, 1), thread (1, 1)\n",
            "Hello World from block (0, 1), thread (2, 1)\n",
            "Hello World from block (0, 1), thread (3, 1)\n",
            "Hello World from block (0, 1), thread (0, 2)\n",
            "Hello World from block (0, 1), thread (1, 2)\n",
            "Hello World from block (0, 1), thread (2, 2)\n",
            "Hello World from block (0, 1), thread (3, 2)\n",
            "Hello World from block (0, 1), thread (0, 3)\n",
            "Hello World from block (0, 1), thread (1, 3)\n",
            "Hello World from block (0, 1), thread (2, 3)\n",
            "Hello World from block (0, 1), thread (3, 3)\n",
            "Hello World from block (0, 0), thread (0, 0)\n",
            "Hello World from block (0, 0), thread (1, 0)\n",
            "Hello World from block (0, 0), thread (2, 0)\n",
            "Hello World from block (0, 0), thread (3, 0)\n",
            "Hello World from block (0, 0), thread (0, 1)\n",
            "Hello World from block (0, 0), thread (1, 1)\n",
            "Hello World from block (0, 0), thread (2, 1)\n",
            "Hello World from block (0, 0), thread (3, 1)\n",
            "Hello World from block (0, 0), thread (0, 2)\n",
            "Hello World from block (0, 0), thread (1, 2)\n",
            "Hello World from block (0, 0), thread (2, 2)\n",
            "Hello World from block (0, 0), thread (3, 2)\n",
            "Hello World from block (0, 0), thread (0, 3)\n",
            "Hello World from block (0, 0), thread (1, 3)\n",
            "Hello World from block (0, 0), thread (2, 3)\n",
            "Hello World from block (0, 0), thread (3, 3)\n",
            "Hello World from block (1, 1), thread (0, 0)\n",
            "Hello World from block (1, 1), thread (1, 0)\n",
            "Hello World from block (1, 1), thread (2, 0)\n",
            "Hello World from block (1, 1), thread (3, 0)\n",
            "Hello World from block (1, 1), thread (0, 1)\n",
            "Hello World from block (1, 1), thread (1, 1)\n",
            "Hello World from block (1, 1), thread (2, 1)\n",
            "Hello World from block (1, 1), thread (3, 1)\n",
            "Hello World from block (1, 1), thread (0, 2)\n",
            "Hello World from block (1, 1), thread (1, 2)\n",
            "Hello World from block (1, 1), thread (2, 2)\n",
            "Hello World from block (1, 1), thread (3, 2)\n",
            "Hello World from block (1, 1), thread (0, 3)\n",
            "Hello World from block (1, 1), thread (1, 3)\n",
            "Hello World from block (1, 1), thread (2, 3)\n",
            "Hello World from block (1, 1), thread (3, 3)\n",
            "Hello World from block (1, 0), thread (0, 0)\n",
            "Hello World from block (1, 0), thread (1, 0)\n",
            "Hello World from block (1, 0), thread (2, 0)\n",
            "Hello World from block (1, 0), thread (3, 0)\n",
            "Hello World from block (1, 0), thread (0, 1)\n",
            "Hello World from block (1, 0), thread (1, 1)\n",
            "Hello World from block (1, 0), thread (2, 1)\n",
            "Hello World from block (1, 0), thread (3, 1)\n",
            "Hello World from block (1, 0), thread (0, 2)\n",
            "Hello World from block (1, 0), thread (1, 2)\n",
            "Hello World from block (1, 0), thread (2, 2)\n",
            "Hello World from block (1, 0), thread (3, 2)\n",
            "Hello World from block (1, 0), thread (0, 3)\n",
            "Hello World from block (1, 0), thread (1, 3)\n",
            "Hello World from block (1, 0), thread (2, 3)\n",
            "Hello World from block (1, 0), thread (3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Xbbvswa9Azr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rcLVkRXp9EcZ"
      }
    }
  ]
}